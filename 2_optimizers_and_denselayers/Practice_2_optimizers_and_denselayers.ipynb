{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY2P_K6PbR4U"
   },
   "source": [
    "# Keywords: modules, optimizers, dense layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UwJ0fPUb24R"
   },
   "source": [
    "# High Level Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A339bun3b6LD"
   },
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrNck7Vsb-gK"
   },
   "source": [
    "Modules help to organize and composing functions and inputs (weights) together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bHh0RNT6bQa8"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn.modules import loss\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6xmxvkJcTRA"
   },
   "source": [
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YbIVrzkecL3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=10, bias=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 input features 10 output features\n",
    "linear = nn.Linear(10, 10)\n",
    "linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WqASjjZQckL3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3224,  2.9591, -1.2117, -1.4629, -3.3487, -3.0964,  3.9498,  2.3097,\n",
       "         0.1073, -0.0669], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.tensor([1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uJcHLHt6cXAS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UzrQBmD6cfr5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0])\n",
    "relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "t4CehSLxcjyY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tanh()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh = nn.Tanh()\n",
    "tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gfNrJGRnc1po"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.5, inplace=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = nn.Dropout(0.5)\n",
    "dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5RFklgV1c3Lp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=100, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential = nn.Sequential(nn.Linear(10, 100), nn.Tanh(), nn.Linear(100,100), nn.Tanh(), nn.Linear(100,10))\n",
    "sequential\n",
    "\n",
    "# No activaiton at the end, because its embedded in the loss function (softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TH30QbbVc41R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lin1): Linear(in_features=10, out_features=100, bias=True)\n",
       "  (act1): Tanh()\n",
       "  (lin2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (lin3): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (lin4): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note about this syntax; not simple assignment, there is magic. If you want to build your own combinat\n",
    "# combination model you should always follows this structure\n",
    "# Dictionary exists of all submodules\n",
    "# Explicit creation of the layer inside the class\n",
    "# Just always follow this structure (behind the scenes magic)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin1 = nn.Linear(10,100)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.lin2 = nn.Linear(100,100)\n",
    "        self.lin3 = nn.Linear(100,100)\n",
    "        self.lin4 = nn.Linear(100,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin4(x)\n",
    "        return x\n",
    "net = Net()\n",
    "net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9hJXnvzvc677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy = loss.CrossEntropyLoss()\n",
    "cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PakWOAlNHa8f"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3ZaSSef3Hc7F"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoNdfuByg9BX"
   },
   "source": [
    "We can define our own modules subclassing `Module` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "976DWqIQiAYu"
   },
   "source": [
    "Modules can have constant parameters (arguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nhScgmbhF-rs"
   },
   "outputs": [],
   "source": [
    "class Power(Module):\n",
    "\n",
    "    __constants__ = ['exponent']\n",
    "\n",
    "    def __init__(self, exponent=3):\n",
    "        super().__init__()\n",
    "        self.exponent = exponent\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.pow(input, self.exponent)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'exponent={self.exponent}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nhScgmbhF-rs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2+1=3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f-strings\n",
    "f'2+1={2+1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wW4Gq_4XObIv"
   },
   "outputs": [],
   "source": [
    "power=Power(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "J_ipLzDhOrKA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power(exponent=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "J_ipLzDhOrKA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power(exponent=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lU_Z2JyMOeb-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power(torch.Tensor([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayd8275PiSa_"
   },
   "source": [
    "and trainable parameters (weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "m1uAg4zzGrWc"
   },
   "outputs": [],
   "source": [
    "class WPower(Module):    \n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.exponent = Parameter(torch.Tensor(1))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.uniform_(self.exponent, a=math.sqrt(5), b=math.sqrt(5))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.pow(input, self.exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "m1uAg4zzGrWc"
   },
   "outputs": [],
   "source": [
    "wpower = WPower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "m1uAg4zzGrWc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([2.2361], requires_grad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(wpower.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "m1uAg4zzGrWc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([2.2361], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpower.exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YemfgVcdIFB"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeszfvqidJ_o"
   },
   "source": [
    "Some models are not just functions, but they also have internal parameters (weights/graph inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "jbYduaVOdDID"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1704, -0.0404,  0.1710, -0.2808,  0.1290, -0.3010, -0.3140,  0.2283,\n",
       "           0.2772,  0.3093],\n",
       "         [ 0.0412,  0.0050,  0.0316,  0.0470,  0.2605, -0.1316,  0.1251,  0.0133,\n",
       "           0.0953, -0.2742],\n",
       "         [ 0.1289, -0.0424, -0.2528, -0.1431,  0.1451, -0.0101,  0.1580, -0.1962,\n",
       "          -0.0455,  0.0123],\n",
       "         [ 0.2438,  0.0730,  0.0704,  0.1396,  0.3109, -0.1872, -0.0280, -0.2803,\n",
       "          -0.0673,  0.0817],\n",
       "         [-0.2456, -0.0475,  0.2896,  0.1526, -0.2902, -0.2245, -0.2805, -0.2099,\n",
       "           0.1861,  0.2295],\n",
       "         [ 0.0810,  0.1179,  0.2155, -0.2657,  0.1832, -0.0657, -0.2112, -0.2090,\n",
       "          -0.0533, -0.1263],\n",
       "         [-0.2168,  0.3054,  0.0500,  0.1813,  0.2717, -0.2287,  0.2313,  0.0644,\n",
       "           0.0430, -0.2158],\n",
       "         [ 0.2507,  0.2118, -0.1789, -0.3148, -0.0510,  0.1905,  0.2485,  0.2159,\n",
       "          -0.0805, -0.1074],\n",
       "         [ 0.0869,  0.3048,  0.2029,  0.0479, -0.1126, -0.1449, -0.2991,  0.1203,\n",
       "           0.1624,  0.0683],\n",
       "         [ 0.2342, -0.1665,  0.1946, -0.1129, -0.0188,  0.1594, -0.1560,  0.0841,\n",
       "          -0.0283, -0.2106]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2216,  0.2721,  0.2837, -0.0095,  0.2789,  0.1104,  0.1728, -0.1986,\n",
       "         -0.2868, -0.2884], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(linear.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FmgsM_OedbPR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1704, -0.0404,  0.1710, -0.2808,  0.1290, -0.3010, -0.3140,  0.2283,\n",
       "          0.2772,  0.3093],\n",
       "        [ 0.0412,  0.0050,  0.0316,  0.0470,  0.2605, -0.1316,  0.1251,  0.0133,\n",
       "          0.0953, -0.2742],\n",
       "        [ 0.1289, -0.0424, -0.2528, -0.1431,  0.1451, -0.0101,  0.1580, -0.1962,\n",
       "         -0.0455,  0.0123],\n",
       "        [ 0.2438,  0.0730,  0.0704,  0.1396,  0.3109, -0.1872, -0.0280, -0.2803,\n",
       "         -0.0673,  0.0817],\n",
       "        [-0.2456, -0.0475,  0.2896,  0.1526, -0.2902, -0.2245, -0.2805, -0.2099,\n",
       "          0.1861,  0.2295],\n",
       "        [ 0.0810,  0.1179,  0.2155, -0.2657,  0.1832, -0.0657, -0.2112, -0.2090,\n",
       "         -0.0533, -0.1263],\n",
       "        [-0.2168,  0.3054,  0.0500,  0.1813,  0.2717, -0.2287,  0.2313,  0.0644,\n",
       "          0.0430, -0.2158],\n",
       "        [ 0.2507,  0.2118, -0.1789, -0.3148, -0.0510,  0.1905,  0.2485,  0.2159,\n",
       "         -0.0805, -0.1074],\n",
       "        [ 0.0869,  0.3048,  0.2029,  0.0479, -0.1126, -0.1449, -0.2991,  0.1203,\n",
       "          0.1624,  0.0683],\n",
       "        [ 0.2342, -0.1665,  0.1946, -0.1129, -0.0188,  0.1594, -0.1560,  0.0841,\n",
       "         -0.0283, -0.2106]], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "y5f0Q3GCdeHC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2216,  0.2721,  0.2837, -0.0095,  0.2789,  0.1104,  0.1728, -0.1986,\n",
       "        -0.2868, -0.2884], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eoSzZUpfdgDl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tanh.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "I-sapuItdiYV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dropout.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Aet5UQbydkp1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout.p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Fsdfce82dtQl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cross_entropy.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BQT6wYz8dpPH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([100, 10]),\n",
       " torch.Size([100]),\n",
       " torch.Size([100, 100]),\n",
       " torch.Size([100]),\n",
       " torch.Size([10, 100]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.shape, list(sequential.parameters())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FtxKoxdfdmsJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([100, 10]),\n",
       " torch.Size([100]),\n",
       " torch.Size([100, 100]),\n",
       " torch.Size([100]),\n",
       " torch.Size([100, 100]),\n",
       " torch.Size([100]),\n",
       " torch.Size([10, 100]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.shape, list(net.parameters())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "H3SN19HOdrow"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.requires_grad, list(net.parameters())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8zULEKKd37v"
   },
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqPenEPGd7U5"
   },
   "source": [
    "Each module can be in either `eval` or `train` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wFPY0TRNd6Kn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.5, inplace=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "YPk0cHNqdw51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 2., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(torch.ones(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "o1JnLrcLeFYL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.5, inplace=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OT0hgQ5PeG_j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 4., 0., 0., 4., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newseq = nn.Sequential(nn.Dropout(), nn.Dropout())\n",
    "newseq(torch.ones(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "kETqU1poeKMr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newseq.eval()\n",
    "newseq(torch.ones(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxeKQ3r0eP9a"
   },
   "source": [
    "**Important**! Train/eval mode has nothing to do with weight training. It just changes the behavior of some modules (i.e. `dropout`, `batchnorm`). For composite modules `.eval()`/`.train()` sets the corresponding mode for each of its components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7rIS3A3etBO"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyKkp9pcewGR"
   },
   "source": [
    "Most modules have a default way of parameter initialization, but sometimes we might want to init them explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "OKX8XpoPer3N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1704, -0.0404,  0.1710, -0.2808,  0.1290, -0.3010, -0.3140,  0.2283,\n",
       "          0.2772,  0.3093],\n",
       "        [ 0.0412,  0.0050,  0.0316,  0.0470,  0.2605, -0.1316,  0.1251,  0.0133,\n",
       "          0.0953, -0.2742],\n",
       "        [ 0.1289, -0.0424, -0.2528, -0.1431,  0.1451, -0.0101,  0.1580, -0.1962,\n",
       "         -0.0455,  0.0123],\n",
       "        [ 0.2438,  0.0730,  0.0704,  0.1396,  0.3109, -0.1872, -0.0280, -0.2803,\n",
       "         -0.0673,  0.0817],\n",
       "        [-0.2456, -0.0475,  0.2896,  0.1526, -0.2902, -0.2245, -0.2805, -0.2099,\n",
       "          0.1861,  0.2295],\n",
       "        [ 0.0810,  0.1179,  0.2155, -0.2657,  0.1832, -0.0657, -0.2112, -0.2090,\n",
       "         -0.0533, -0.1263],\n",
       "        [-0.2168,  0.3054,  0.0500,  0.1813,  0.2717, -0.2287,  0.2313,  0.0644,\n",
       "          0.0430, -0.2158],\n",
       "        [ 0.2507,  0.2118, -0.1789, -0.3148, -0.0510,  0.1905,  0.2485,  0.2159,\n",
       "         -0.0805, -0.1074],\n",
       "        [ 0.0869,  0.3048,  0.2029,  0.0479, -0.1126, -0.1449, -0.2991,  0.1203,\n",
       "          0.1624,  0.0683],\n",
       "        [ 0.2342, -0.1665,  0.1946, -0.1129, -0.0188,  0.1594, -0.1560,  0.0841,\n",
       "         -0.0283, -0.2106]], requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "m8LyFiCweOYu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1958, -0.1595,  0.3427,  0.4242, -0.4070, -0.4242,  0.3320,  0.2851,\n",
       "          0.3684, -0.3191],\n",
       "        [-0.3988,  0.3242,  0.2398,  0.1060,  0.1527, -0.0508,  0.1541, -0.3472,\n",
       "          0.4252,  0.5287],\n",
       "        [-0.4204,  0.2371, -0.3314,  0.2692,  0.3058, -0.2146, -0.4615,  0.4735,\n",
       "         -0.5070,  0.0419],\n",
       "        [ 0.2034,  0.5189, -0.4307,  0.0676,  0.5296,  0.1828, -0.2545, -0.0506,\n",
       "          0.4570, -0.0273],\n",
       "        [ 0.3253, -0.2283,  0.2958,  0.2991, -0.2788, -0.4593, -0.4390, -0.0132,\n",
       "         -0.0478, -0.5015],\n",
       "        [-0.1005,  0.1150,  0.3021,  0.4557,  0.5088,  0.1528, -0.4027,  0.4997,\n",
       "         -0.0647,  0.5144],\n",
       "        [-0.2200, -0.1708,  0.4890, -0.0505,  0.1224,  0.1502, -0.3104,  0.4652,\n",
       "          0.4468,  0.2198],\n",
       "        [-0.0950, -0.1822, -0.0594,  0.4100, -0.3936, -0.1819, -0.0181,  0.3757,\n",
       "          0.3996, -0.5018],\n",
       "        [-0.3657, -0.2017,  0.5439, -0.0886,  0.3874, -0.2452,  0.4325,  0.0142,\n",
       "          0.1704,  0.3020],\n",
       "        [-0.2035,  0.3080,  0.2135,  0.0399, -0.3050, -0.1299,  0.3156,  0.4669,\n",
       "         -0.4226,  0.4965]], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.xavier_uniform_(linear.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "og6vAbZvfHRV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.constant_(linear.weight, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "c6X6oRr2fJ6j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2216,  0.2721,  0.2837, -0.0095,  0.2789,  0.1104,  0.1728, -0.1986,\n",
       "         -0.2868, -0.2884], requires_grad=True)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(linear.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "-NcEej-6fL5H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ -7.1392,  11.8878,  -3.7133,   2.9738,  -1.8304,  10.5991,  -1.6181,\n",
       "            2.7477,  -0.7197,  -1.4729],\n",
       "         [ -3.7708,  -8.4758,  -8.7529,  -8.5825,   8.9000,   9.7932,  -5.8744,\n",
       "            6.0912,  -2.7552,   4.3440],\n",
       "         [  6.0895,   8.7568,   6.9104,   2.5997,   1.6281,   1.2908,   6.9638,\n",
       "            9.7513,  -2.2097,   6.5017],\n",
       "         [  8.2510,  10.0226,   5.6413,  -1.0476,   3.6533,  11.6600,  -6.8923,\n",
       "            6.3612,  -9.3393,   1.0613],\n",
       "         [  8.1898,  10.1593,  -3.5385,  10.5986,  -9.7591,   7.0280,  -5.6122,\n",
       "            0.3114,   0.0574,  -5.6232],\n",
       "         [  2.5647,   8.8914, -11.6072, -11.0234,   8.1807,  -9.0384,   0.0891,\n",
       "           -9.6596,   3.9200,   2.5331],\n",
       "         [ 10.4125, -10.3309,  11.3378,   2.2952,  11.2904,   3.0119, -11.1334,\n",
       "           -5.4926,  -3.6783,  11.7763],\n",
       "         [ -5.1285,  -1.3147, -11.9227,  -8.1250,  -3.9471,   2.5215,  -1.0286,\n",
       "            4.6322,  -6.7091,   2.5997],\n",
       "         [ -7.0111,   7.0726,   7.1612,   7.4274,   3.8507,   6.2323,   0.4498,\n",
       "           11.3791,   0.9907,  -7.5441],\n",
       "         [ -2.7756,   9.4266,   7.5338,  -5.1648,   7.5485,   1.3049,  -1.4775,\n",
       "            1.1330,  11.9294,   1.4769]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 11.7787, -10.2173,   4.0887,   9.8342,   2.3000,   8.9376,  -4.2701,\n",
       "           0.3053,   0.2813,  -9.5128], requires_grad=True)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in linear.parameters():\n",
    "    init.uniform_(param, -12, 12)\n",
    "list(linear.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bczsQJD_fXJF"
   },
   "source": [
    "[link text](https://)You can find more initialization functions here: https://pytorch.org/docs/master/nn.html#torch-nn-init."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-HlBUMMfooa"
   },
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QcAvjRJfvsT"
   },
   "source": [
    "Torch has a reach collection of optimizers built-in, but for now we will use just a vanilla stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "7D4SLAamfONk"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "5_zpzWMggMHz"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "MfWQxhE3gOC6"
   },
   "outputs": [],
   "source": [
    "sgd = optim.SGD([x], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "80K1tz4ugP_s"
   },
   "outputs": [],
   "source": [
    "y = x * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "zS49qBGzgTEW"
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "M0nHcNqVgWRe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "CuVGUuqPgYTo"
   },
   "outputs": [],
   "source": [
    "sgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "sr-tEtKEgaIS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8000], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "V0dKVjoYgb_n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-HkkGT9igdst"
   },
   "outputs": [],
   "source": [
    "sgd.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "r8eRwxRQgfNi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bbVM2MHgiWQ"
   },
   "source": [
    "# First Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "wIFr-KUjgmR_"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKSiYasbgrQ3"
   },
   "source": [
    "Let's downlad MNIST --- dataset of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "0CaQGiyMgrnT"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "G3h5RcNngxnI"
   },
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST('../data', train=False, download=True,\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VreNjs_ghAEI"
   },
   "source": [
    "Dataloaders are responsible for data loading. They help us to split dataset in batches and shuffles the dataset(otherwise each buch will have only variants of a single digit). We will look inside them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "isUaEilOg79-"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "2JwLAUASg-3u"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "toPIL = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "tNt3vzcWheef"
   },
   "outputs": [],
   "source": [
    "def example(i):\n",
    "    print(train_dataset[i][1])\n",
    "    return toPIL(train_dataset[i][0]).resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "FT3VcfTNhg9S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x7FB83DE06EB0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "ukAEeDcShinq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 2, 4, 9, 0, 8, 1, 2, 4, 1, 3, 5, 6, 6, 4, 8, 0, 1, 5, 7, 6, 6, 8, 7,\n",
       "        6, 7, 2, 4, 8, 8, 2, 2, 0, 3, 0, 1, 0, 9, 7, 1, 7, 4, 1, 3, 0, 2, 1, 8,\n",
       "        7, 3, 3, 3, 1, 0, 9, 7, 7, 8, 6, 8, 7, 2, 3, 6])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__iter__().__next__()[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "u2xbqs4CiAxN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__iter__().__next__()[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "hBOrXp1ZiDQm"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x7FB8329D87F0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toPIL(train_loader.__iter__().__next__()[0][0]).resize((256,256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MU728eD_iVwF"
   },
   "source": [
    "Let's write a simple helper module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "drFE7ng0iaY2"
   },
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.view(batch_size, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      nn.Linear(784, 512), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(512, 64), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(64, 10))\n",
    "for param in model.parameters():\n",
    "    init.uniform_(param, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8q6alogikey"
   },
   "source": [
    "Why do we need `Flatten` module?\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1ioiHwWiriu"
   },
   "source": [
    "Setup an optimizer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "F_ZaRtLhiQpL"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuGF-VaJixR-"
   },
   "source": [
    "Choose a loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "97rK7imziwi7"
   },
   "outputs": [],
   "source": [
    "loss_function = loss.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tY1JXkwsi4B7"
   },
   "source": [
    "And start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "uTGlEEUsi21g"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss_function, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "YJZcV3I1it47"
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_function):\n",
    "    \n",
    "    incorrect_pred_idx=[]\n",
    "    incorrect_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, [data, target] in enumerate(test_loader):\n",
    "            output = model(data)\n",
    "            test_loss += loss_function(output, target).sum().item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            # Store wrongly predicted images\n",
    "            wrong_idx = (pred != target.view_as(pred)).nonzero()[:, 0]\n",
    "            if wrong_idx.nelement() != 0:\n",
    "                wrong_pred = pred[wrong_idx]\n",
    "                incorrect_pred_idx.append(wrong_idx)\n",
    "                incorrect_pred.append(wrong_pred)\n",
    "                \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return incorrect_pred_idx, incorrect_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "DMHY4BfdjJFr",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  for epoch in range(1, 20):\n",
    "#         train(model, train_loader, optimizer, loss_function, epoch)\n",
    "#         test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v18YmlwUoxY8"
   },
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W20EUe7AxioK"
   },
   "source": [
    "## Due to 8AM, 25.05.2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mO6zst4UpcMR"
   },
   "source": [
    "## 1. MNIST playground [10]\n",
    "\n",
    "**Important!** This task is not too hard, but it is pretty time-consuming. Total computation time is about 4 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "##### 1. Find out how many epochs are needed for our network to stop improving on test dataset (let's stop on 5 epochs without accuracy improvement on the test set). How long does it take? [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "It takes about 30 seconds, or 5 epochs, before the accuracy stops improving significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.327771\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.304363\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.278540\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.186084\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.225507\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 9538/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.047927\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.105109\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.102747\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.122402\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.177707\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9653/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.061931\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.057408\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.044469\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.018160\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.045129\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 9677/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.016354\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.020341\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.094656\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.018319\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.018816\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 9756/10000 (98%)\n",
      "\n",
      "CPU times: user 3min 55s, sys: 446 ms, total: 3min 56s\n",
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    incorrect_pred_idx, incorrect_pred = test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "##### 2. Find some problematic examples and show them with `example()` function we defined in class.[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[9],\n",
       "         [8]]),\n",
       " tensor([[9]]),\n",
       " tensor([[2],\n",
       "         [8],\n",
       "         [9]]),\n",
       " tensor([[7],\n",
       "         [9]]),\n",
       " tensor([[3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [2]]),\n",
       " tensor([[8]]),\n",
       " tensor([[5]]),\n",
       " tensor([[6],\n",
       "         [5]]),\n",
       " tensor([[3]]),\n",
       " tensor([[3]]),\n",
       " tensor([[3]]),\n",
       " tensor([[6]]),\n",
       " tensor([[8]]),\n",
       " tensor([[8],\n",
       "         [7],\n",
       "         [7],\n",
       "         [1]]),\n",
       " tensor([[6]]),\n",
       " tensor([[3],\n",
       "         [4],\n",
       "         [4]]),\n",
       " tensor([[3],\n",
       "         [2]]),\n",
       " tensor([[8],\n",
       "         [8]]),\n",
       " tensor([[4],\n",
       "         [0],\n",
       "         [8]]),\n",
       " tensor([[3],\n",
       "         [0]]),\n",
       " tensor([[9]]),\n",
       " tensor([[6],\n",
       "         [3],\n",
       "         [8]]),\n",
       " tensor([[3],\n",
       "         [4],\n",
       "         [9]]),\n",
       " tensor([[7]]),\n",
       " tensor([[7]]),\n",
       " tensor([[4],\n",
       "         [4],\n",
       "         [5]]),\n",
       " tensor([[7]]),\n",
       " tensor([[3],\n",
       "         [7]]),\n",
       " tensor([[2],\n",
       "         [7]]),\n",
       " tensor([[5]]),\n",
       " tensor([[3],\n",
       "         [6]]),\n",
       " tensor([[3]]),\n",
       " tensor([[4]]),\n",
       " tensor([[8],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6]]),\n",
       " tensor([[2]]),\n",
       " tensor([[8],\n",
       "         [3],\n",
       "         [8]]),\n",
       " tensor([[3]]),\n",
       " tensor([[3],\n",
       "         [6],\n",
       "         [7]]),\n",
       " tensor([[6]]),\n",
       " tensor([[3],\n",
       "         [2],\n",
       "         [0],\n",
       "         [7]]),\n",
       " tensor([[8],\n",
       "         [3],\n",
       "         [0]]),\n",
       " tensor([[2],\n",
       "         [2],\n",
       "         [3],\n",
       "         [5]]),\n",
       " tensor([[7],\n",
       "         [2]]),\n",
       " tensor([[3],\n",
       "         [8]]),\n",
       " tensor([[2],\n",
       "         [8],\n",
       "         [9],\n",
       "         [6]]),\n",
       " tensor([[3]]),\n",
       " tensor([[8],\n",
       "         [3]]),\n",
       " tensor([[9],\n",
       "         [5],\n",
       "         [5]]),\n",
       " tensor([[2],\n",
       "         [6]]),\n",
       " tensor([[3],\n",
       "         [5],\n",
       "         [2]]),\n",
       " tensor([[9],\n",
       "         [6]]),\n",
       " tensor([[1]]),\n",
       " tensor([[8],\n",
       "         [0],\n",
       "         [9]]),\n",
       " tensor([[9],\n",
       "         [4]]),\n",
       " tensor([[6],\n",
       "         [8]]),\n",
       " tensor([[3]]),\n",
       " tensor([[7],\n",
       "         [2],\n",
       "         [3]]),\n",
       " tensor([[2],\n",
       "         [6],\n",
       "         [9],\n",
       "         [0]]),\n",
       " tensor([[9]]),\n",
       " tensor([[0],\n",
       "         [8]]),\n",
       " tensor([[4],\n",
       "         [3]]),\n",
       " tensor([[3]]),\n",
       " tensor([[9],\n",
       "         [4]]),\n",
       " tensor([[6],\n",
       "         [3],\n",
       "         [9],\n",
       "         [0]]),\n",
       " tensor([[3],\n",
       "         [2]]),\n",
       " tensor([[9]]),\n",
       " tensor([[1]]),\n",
       " tensor([[8],\n",
       "         [7],\n",
       "         [8]]),\n",
       " tensor([[3],\n",
       "         [3],\n",
       "         [1],\n",
       "         [4],\n",
       "         [5],\n",
       "         [0]]),\n",
       " tensor([[0]]),\n",
       " tensor([[7]]),\n",
       " tensor([[3]]),\n",
       " tensor([[1],\n",
       "         [8],\n",
       "         [9]]),\n",
       " tensor([[3],\n",
       "         [2]]),\n",
       " tensor([[4]]),\n",
       " tensor([[0]]),\n",
       " tensor([[2],\n",
       "         [2]]),\n",
       " tensor([[9],\n",
       "         [9],\n",
       "         [3]]),\n",
       " tensor([[3]]),\n",
       " tensor([[9]]),\n",
       " tensor([[3]]),\n",
       " tensor([[2],\n",
       "         [8],\n",
       "         [3]]),\n",
       " tensor([[8],\n",
       "         [6]]),\n",
       " tensor([[0]]),\n",
       " tensor([[9]]),\n",
       " tensor([[0]]),\n",
       " tensor([[7]]),\n",
       " tensor([[0],\n",
       "         [4],\n",
       "         [3]]),\n",
       " tensor([[8]]),\n",
       " tensor([[3]]),\n",
       " tensor([[2],\n",
       "         [3],\n",
       "         [4]]),\n",
       " tensor([[5],\n",
       "         [9],\n",
       "         [2]]),\n",
       " tensor([[1],\n",
       "         [6]]),\n",
       " tensor([[3],\n",
       "         [0],\n",
       "         [3],\n",
       "         [9]]),\n",
       " tensor([[1],\n",
       "         [3],\n",
       "         [4]]),\n",
       " tensor([[2],\n",
       "         [9],\n",
       "         [5],\n",
       "         [0]]),\n",
       " tensor([[7],\n",
       "         [9]]),\n",
       " tensor([[9],\n",
       "         [3],\n",
       "         [1]]),\n",
       " tensor([[8]]),\n",
       " tensor([[3],\n",
       "         [9],\n",
       "         [4],\n",
       "         [3]]),\n",
       " tensor([[8],\n",
       "         [3]]),\n",
       " tensor([[4],\n",
       "         [9]]),\n",
       " tensor([[8],\n",
       "         [2]]),\n",
       " tensor([[3]]),\n",
       " tensor([[3],\n",
       "         [0]]),\n",
       " tensor([[9],\n",
       "         [6],\n",
       "         [5]]),\n",
       " tensor([[4]]),\n",
       " tensor([[8]]),\n",
       " tensor([[8],\n",
       "         [0],\n",
       "         [0]]),\n",
       " tensor([[4],\n",
       "         [3]]),\n",
       " tensor([[6],\n",
       "         [4]]),\n",
       " tensor([[6],\n",
       "         [7]]),\n",
       " tensor([[0]]),\n",
       " tensor([[9],\n",
       "         [7]]),\n",
       " tensor([[8]]),\n",
       " tensor([[2],\n",
       "         [2]]),\n",
       " tensor([[8]]),\n",
       " tensor([[3],\n",
       "         [3]]),\n",
       " tensor([[3]]),\n",
       " tensor([[7],\n",
       "         [0]]),\n",
       " tensor([[9]])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "def example_train(i):\n",
    "    print(train_dataset[i][1])\n",
    "    return toPIL(train_dataset[i][0]).resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "def example_test(i):\n",
    "    print(test_dataset[i][1])\n",
    "    test_dataset[i][1].label\n",
    "    return toPIL(test_dataset[i][0]).resize((256, 256)), labelx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([10, 24]),\n",
       " tensor([36]),\n",
       " tensor([ 4, 18, 32]),\n",
       " tensor([36, 50]),\n",
       " tensor([14, 30, 33, 44, 46]),\n",
       " tensor([51]),\n",
       " tensor([48]),\n",
       " tensor([27, 56]),\n",
       " tensor([23]),\n",
       " tensor([53])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_pred_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 24])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_pred_idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can scroll through incorrect examples by chaning the wrong_idx var,        and running this cell and the next one\n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x7FB83DDE4F10>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('can scroll through incorrect examples by chaning the wrong_idx var, \\\n",
    "       and running this cell and the next one')\n",
    "\n",
    "wrong_idx = 30\n",
    "\n",
    "sample_number = incorrect_pred_idx[wrong_idx].numpy()[0]\n",
    "example_train(sample_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect sample number:  25\n",
      "The predicted class for this number was:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Incorrect sample number: ', sample_number)\n",
    "print('The predicted class for this number was:')\n",
    "\n",
    "incorrect_pred[sample_number].numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "##### 3. Draw a confusion matrix for your model on test dataset. It is a 10x10 matrix, and in the cell `(i,j)` there is a number of digits `i` classified as digit `j`.[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10000)\n",
    "    train_preds = get_all_preds(model, prediction_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5],\n",
       "        [0, 0],\n",
       "        [4, 4],\n",
       "        ...,\n",
       "        [5, 5],\n",
       "        [6, 6],\n",
       "        [8, 8]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = torch.stack(\n",
    "    (\n",
    "        train_dataset.targets\n",
    "        ,train_preds.argmax(dim=1)\n",
    "    )\n",
    "    ,dim=1\n",
    ")\n",
    "\n",
    "stacked.shape\n",
    "torch.Size([60000, 2])\n",
    "\n",
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmt = torch.zeros(10,10, dtype=torch.int64)\n",
    "cmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "for p in stacked:\n",
    "    tl, pl = p.tolist()\n",
    "    cmt[tl, pl] = cmt[tl, pl] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5907,    1,    0,    2,    2,    0,    4,    0,    4,    3],\n",
       "        [   0, 6693,    8,    9,    5,    1,    1,   13,    4,    8],\n",
       "        [   3,    2, 5934,    4,    4,    0,    0,    5,    5,    1],\n",
       "        [   0,    0,   10, 6100,    1,    4,    0,    2,   10,    4],\n",
       "        [   2,    2,    3,    0, 5771,    0,    5,    2,    3,   54],\n",
       "        [   0,    0,    1,   24,    2, 5369,    9,    0,    8,    8],\n",
       "        [   9,    1,    2,    0,    6,    4, 5886,    0,   10,    0],\n",
       "        [   1,    6,    7,    5,    7,    0,    0, 6225,    1,   13],\n",
       "        [   3,    7,    2,   12,    0,    3,    1,    2, 5820,    1],\n",
       "        [   4,    1,    0,    5,   13,    1,    0,    8,    5, 5912]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5907,    1,    0,    2,    2,    0,    4,    0,    4,    3],\n",
       "       [   0, 6693,    8,    9,    5,    1,    1,   13,    4,    8],\n",
       "       [   3,    2, 5934,    4,    4,    0,    0,    5,    5,    1],\n",
       "       [   0,    0,   10, 6100,    1,    4,    0,    2,   10,    4],\n",
       "       [   2,    2,    3,    0, 5771,    0,    5,    2,    3,   54],\n",
       "       [   0,    0,    1,   24,    2, 5369,    9,    0,    8,    8],\n",
       "       [   9,    1,    2,    0,    6,    4, 5886,    0,   10,    0],\n",
       "       [   1,    6,    7,    5,    7,    0,    0, 6225,    1,   13],\n",
       "       [   3,    7,    2,   12,    0,    3,    1,    2, 5820,    1],\n",
       "       [   4,    1,    0,    5,   13,    1,    0,    8,    5, 5912]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(train_dataset.targets, train_preds.argmax(dim=1))\n",
    "print(type(cm))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[5907    1    0    2    2    0    4    0    4    3]\n",
      " [   0 6693    8    9    5    1    1   13    4    8]\n",
      " [   3    2 5934    4    4    0    0    5    5    1]\n",
      " [   0    0   10 6100    1    4    0    2   10    4]\n",
      " [   2    2    3    0 5771    0    5    2    3   54]\n",
      " [   0    0    1   24    2 5369    9    0    8    8]\n",
      " [   9    1    2    0    6    4 5886    0   10    0]\n",
      " [   1    6    7    5    7    0    0 6225    1   13]\n",
      " [   3    7    2   12    0    3    1    2 5820    1]\n",
      " [   4    1    0    5   13    1    0    8    5 5912]]\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "##### 4. By default weight of linear layer is initialized with `kaiming_uniform` function and bias is unitialized with `uniform` function (see reset parameters method of Linear class https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py). Initialize all weights as `uniform(-0.1,0.1)` and test. How does this modification affect training process? Is it faster/slower? Is the end result better/worse? Same question form `uniform(-1, 1)`. Same question for `constant(0)` initialization. Don't forget to recreate optimizer for your new model (otherwise you'll optimize parameters of the old model using values from the new one, which does not work).[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "initialize_weight = 0.1\n",
    "\n",
    "class ChildLinear(nn.Linear):\n",
    "    def reset_parameters(self) -> None:\n",
    "        stdv = initialize_weight\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      ChildLinear(784, 512), \n",
    "                      nn.Tanh(),\n",
    "                      ChildLinear(512, 64), \n",
    "                      nn.Tanh(),\n",
    "                      ChildLinear(64, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): ChildLinear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): ChildLinear(in_features=512, out_features=64, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): ChildLinear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.343165\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.343582\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.144371\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.166742\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.310330\n",
      "\n",
      "Test set: Average loss: 0.0025, Accuracy: 9526/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.081811\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.155884\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.134297\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.081770\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.037153\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9681/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.105415\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.078418\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.086743\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.046567\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.025844\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 9683/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.055795\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.083657\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.052304\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.074221\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.024838\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 9757/10000 (98%)\n",
      "\n",
      "CPU times: user 3min 54s, sys: 312 ms, total: 3min 54s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    incorrect_pred_idx, incorrect_pred = pred_list = test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"initialize_weight = 0.1\"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- training deep models is a sufficiently difficult task that most algorithms are strongly affected by the choice of initialization. The initial point can determine whether the algorithm converges at all, with some initial points being so unstable that the algorithm encounters numerical difficulties and fails altogether.\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- The time it takes for 4 epochs is 2 seconds less, maybe it is closer to the best weights this particular initialization.\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "The result is almost equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "initialize_weight = 1\n",
    "\n",
    "class ChildLinear(nn.Linear):\n",
    "    def reset_parameters(self) -> None:\n",
    "        stdv = initialize_weight\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      ChildLinear(784, 512), \n",
    "                      nn.Tanh(),\n",
    "                      ChildLinear(512, 64), \n",
    "                      nn.Tanh(),\n",
    "                      ChildLinear(64, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): ChildLinear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): ChildLinear(in_features=512, out_features=64, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): ChildLinear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 6.795565\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.103507\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.556525\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.720253\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.566370\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 8295/10000 (83%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.479869\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.205330\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.472322\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.487053\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.513957\n",
      "\n",
      "Test set: Average loss: 0.0069, Accuracy: 8653/10000 (87%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.234398\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.389848\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.270156\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.507949\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.457986\n",
      "\n",
      "Test set: Average loss: 0.0063, Accuracy: 8776/10000 (88%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.200086\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.350776\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.406122\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.165654\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.218006\n",
      "\n",
      "Test set: Average loss: 0.0060, Accuracy: 8844/10000 (88%)\n",
      "\n",
      "CPU times: user 3min 52s, sys: 396 ms, total: 3min 53s\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"initialize_weight = 1\"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- This modification ruins the convergence of the training process as the accuracy stays around 89%, so we lost about 9%\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- The time it takes is also longer, probably because the initial weights are far from the ideal values it takes longer to converge\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "As the accuracy does not converge beyond 89% in 4 epochs, so the result is a lot worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "initialize_weight = 0\n",
    "\n",
    "class ChildLinear(nn.Linear):\n",
    "    def reset_parameters(self) -> None:\n",
    "        stdv = initialize_weight\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      ChildLinear(784, 512), \n",
    "                      nn.Tanh(),\n",
    "                      ChildLinear(512, 64), \n",
    "                      nn.Tanh(),\n",
    "                      ChildLinear(64, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): ChildLinear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): ChildLinear(in_features=512, out_features=64, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): ChildLinear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302583\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.292323\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.305702\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.311464\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.305421\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.297701\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.307256\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.295778\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.306251\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.295137\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.315510\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.320227\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.304078\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.308393\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.302799\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.308627\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.300148\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.296325\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.306336\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.295325\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "CPU times: user 3min 51s, sys: 400 ms, total: 3min 51s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"initialize_weight = 0\"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- This modification ruins the convergence of the training process as the accuracy stays around 11%\n",
    "- This could be cause if the initial weights are zero, then the network can barely detect those neurons.\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- The time it takes for 4 epochs is equal to the previous case\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "As the accuracy does not converge beyond 11% the result is a lot worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "##### 5. Try replacing `Tanh` activation by `Sigmoid` test, how does this modification affect training process? These and further questions assumes that you are changing the initial model (i.e. all modification from previous step are undone). [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      nn.Linear(784, 512), \n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(512, 64), \n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(64, 10))\n",
    "for param in model.parameters():\n",
    "    init.uniform_(param, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Sigmoid()\n",
       "  (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (4): Sigmoid()\n",
       "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.367258\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.719022\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.825644\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.531809\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.379528\n",
      "\n",
      "Test set: Average loss: 0.0066, Accuracy: 8811/10000 (88%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.404370\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.359103\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.283456\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.337693\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.229880\n",
      "\n",
      "Test set: Average loss: 0.0048, Accuracy: 9117/10000 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.174228\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.321189\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.215667\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.338313\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.160220\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 9238/10000 (92%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.121837\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.252722\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.365929\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.191532\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.313052\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 9369/10000 (94%)\n",
      "\n",
      "CPU times: user 3min 41s, sys: 44.2 ms, total: 3min 42s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"Sigmoid\"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- The sigmoid function appears in the output layer of the deep learning models and is used for predicting probability-based outputs.\n",
    "- Some of the major drawbacks of the sigmoid function include gradient saturation, slow convergence, sharp damp gradients during backpropagation from within deeper hidden layers to the input layers, and non-zero centered output that causes the gradient updates to propagate in varying directions.\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- The time is 2 seconds faster than our base model\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "As the accuracy does not converge beyond 94%, compared to 98% the result is a lot worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "##### 6. Try changing output dimension of the first linear layer  (and input of the second) to `256`, to `1024`. How does this modification affect training process? How does the number of model parameters changes? [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      nn.Linear(784, 256), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(256, 64), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(64, 10))\n",
    "for param in model.parameters():\n",
    "    init.uniform_(param, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304728\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.379752\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.371282\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.185952\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.244285\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 9382/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.225197\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.118574\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.115873\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.042513\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.097945\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9654/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.054184\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.075638\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.071556\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.071817\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.045486\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9679/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.106961\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.045213\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.016056\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.020771\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.077446\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 9730/10000 (97%)\n",
      "\n",
      "CPU times: user 3min 49s, sys: 647 ms, total: 3min 50s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"First linear layer output 256\"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- There are some empirically-derived rules-of-thumb, of these, the most commonly relied on is 'the optimal size of the hidden layer is usually between the size of the input and size of the output layers'\n",
    "- Therefore a choice of 256 is a fine choice as it is between the size of the input layer and the output layer\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- Equal for reasons stated above\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "- Equal for reasons stated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      nn.Linear(784, 1024), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(1024, 64), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(64, 10))\n",
    "for param in model.parameters():\n",
    "    init.uniform_(param, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=1024, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302829\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.305933\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.375704\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.121127\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.136274\n",
      "\n",
      "Test set: Average loss: 0.0029, Accuracy: 9454/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.313441\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.189958\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.172870\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.141929\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.123993\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 9636/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.041029\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.046995\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.080758\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.108342\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.091366\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 9707/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.022703\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.069471\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.026546\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.047121\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.042804\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 9748/10000 (97%)\n",
      "\n",
      "CPU times: user 4min 3s, sys: 132 ms, total: 4min 3s\n",
      "Wall time: 30.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"First linear layer output 1024\"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- A layer in between the input and output layer larger or lower than in the size of the input or output layer is bad practice and should be avoided.\n",
    "- This can reduce the model complexity when optimizing the neural network, as all the information will have to pass these layers were it will diverge (or converge over a few neurons).\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- The time it takes for 4 epochs is longer than the benchmark base model\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "As the accuracy does not converge beyond 97% the result is a bit worse, which makes sense because 1024 is not that much bigger than 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "##### 7. Our model has 2 hidden layers of sizes `512` and `64`. Let's use 3 hidden layers of sizes `512`, `256` and `64`.  How does this modification affect training process? How does the number of model parameters changes? Same question for 3 layers of sizes `512`, `5` and `64`(don't forget to add activation function between linear layers). [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      nn.Linear(784, 512), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(512, 64), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(64, 32),\n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(32, 10))\n",
    "for param in model.parameters():\n",
    "    init.uniform_(param, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (6): Tanh()\n",
       "  (7): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.315372\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.372823\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.379658\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.429258\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.147671\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 9432/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.158432\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.301684\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.131890\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.051637\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.234587\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 9666/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.126603\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.131010\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.123313\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.150254\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.068375\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 9692/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.027396\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.099201\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.030733\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.016886\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.033103\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 9745/10000 (97%)\n",
      "\n",
      "CPU times: user 3min 51s, sys: 416 ms, total: 3min 52s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"Add  3 hidden layers of sizes `512`, `256` and `64`. \"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- This modification is fine according to the rules of thumb\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- Equal\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "- Equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      nn.Linear(784, 512), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(512, 5), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(5, 64),\n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(64, 10))\n",
    "for param in model.parameters():\n",
    "    init.uniform_(param, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): Linear(in_features=512, out_features=5, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): Linear(in_features=5, out_features=64, bias=True)\n",
       "  (6): Tanh()\n",
       "  (7): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.322958\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.560374\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.405566\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.542819\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.131538\n",
      "\n",
      "Test set: Average loss: 0.0047, Accuracy: 9138/10000 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.397148\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.270165\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.175335\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.151393\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.165130\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 9464/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.159452\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.283069\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.060759\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.224519\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.198942\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 9573/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.118145\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.060959\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.260265\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.138956\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.031747\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 9620/10000 (96%)\n",
      "\n",
      "CPU times: user 3min 56s, sys: 512 ms, total: 3min 56s\n",
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"Add  3 hidden layers of sizes `512`, `5` and `64`. \"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- This modification ruins the model a bit because here is a layer in between with only 5 neurons\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- The time it takes is equal\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "- The accuracy is about equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "##### 8. Try adding dropout after first/second layer. How does this modification affect training process? [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      nn.Linear(784, 512), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.Linear(512, 64), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(64, 10))\n",
    "for param in model.parameters():\n",
    "    init.uniform_(param, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.292633\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.303937\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.444373\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.342879\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.266177\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 9400/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.335613\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.160549\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.207899\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.169904\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.111756\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 9590/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.146918\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.120969\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.142002\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.157770\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.207270\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 9643/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.175825\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.105363\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.203411\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.119067\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.069879\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 9679/10000 (97%)\n",
      "\n",
      "CPU times: user 3min 53s, sys: 472 ms, total: 3min 54s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"Add  dropout \"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- During training, some number of layer outputs are randomly ignored or “dropped out.” This has the effect of making the layer look-like and be treated-like a layer with a different number of nodes and connectivity to the prior layer. In effect, each update to a layer during training is performed with a different “view” of the configured layer.\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- The time it takes for 4 epochs is 0.5 seconds lower than benchmark\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "- The result should be a littlebit better, but is equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "##### 9. Try disabling shuffle in the train dataloader (leave it unchanged in the test dataloader, otherwise testing will not be fair). How does this modification affect training process? Do not forget to reset training weights of the model. [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "isUaEilOg79-"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      nn.Linear(784, 512), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(512, 64), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(64, 10))\n",
    "for param in model.parameters():\n",
    "    init.uniform_(param, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.309062\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.247206\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.217764\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.179675\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.211449\n",
      "\n",
      "Test set: Average loss: 0.0029, Accuracy: 9432/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.111791\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.096746\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.107957\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.090714\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.137758\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 9636/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.054833\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.069503\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.057007\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.058898\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.103682\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 9705/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.035297\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.053515\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.037152\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.042710\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.080994\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 9747/10000 (97%)\n",
      "\n",
      "CPU times: user 3min 50s, sys: 443 ms, total: 3min 50s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, train_loader, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"Stop the train dataset loader from shuffling MNIST data. \"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- According to the web the MNIST dataset is shuffled, so not shuffling it has no effect \n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- The time it takes for 4 epochs is equal to the previous case\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "- Equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "##### 10. Try training, using half of the training dataset. 30%. 10%. How does this affect training process? Do not forget to reset training weights of the model. [1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler, DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "#### So one train data batch is a  tensor of shape: torch.Size([64,1, 28, 28]). This means we have 1000 examples of 28x28 pixels in grayscale (i.e. no rgb channels, hence the one). We can plot some of them using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "iyfJfxlYiGY2"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(Flatten(), \n",
    "                      nn.Linear(784, 512), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(512, 64), \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(64, 10))\n",
    "for param in model.parameters():\n",
    "    init.uniform_(param, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "train_ds = train_dataset\n",
    "num_train_samples = 30000\n",
    "sample_ds = Subset(train_dataset, np.arange(num_train_samples))\n",
    "sample_sampler = RandomSampler(sample_ds)\n",
    "sample_dl = DataLoader(sample_ds, sampler=sample_sampler, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/30000 (0%)]\tLoss: 2.265165\n",
      "Train Epoch: 1 [12800/30000 (43%)]\tLoss: 0.310917\n",
      "Train Epoch: 1 [25600/30000 (85%)]\tLoss: 0.201090\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 9289/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/30000 (0%)]\tLoss: 0.227417\n",
      "Train Epoch: 2 [12800/30000 (43%)]\tLoss: 0.157015\n",
      "Train Epoch: 2 [25600/30000 (85%)]\tLoss: 0.300440\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 9486/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/30000 (0%)]\tLoss: 0.068329\n",
      "Train Epoch: 3 [12800/30000 (43%)]\tLoss: 0.131746\n",
      "Train Epoch: 3 [25600/30000 (85%)]\tLoss: 0.166613\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 9607/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/30000 (0%)]\tLoss: 0.121136\n",
      "Train Epoch: 4 [12800/30000 (43%)]\tLoss: 0.112726\n",
      "Train Epoch: 4 [25600/30000 (85%)]\tLoss: 0.099924\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 9648/10000 (96%)\n",
      "\n",
      "CPU times: user 2min 9s, sys: 464 ms, total: 2min 10s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, sample_dl, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"Use only 50% of the training dataset.\"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- This modification caps the accuracy on the test dataset\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- Using half of the dataset is 2x as fast ofcourse\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "As the accuracy is not so much worse, and the speed is much faster. More epochs result into the same convergence, therefore so far it does not deliver any problems. EQUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "train_ds = train_dataset\n",
    "num_train_samples = 20000\n",
    "sample_ds = Subset(train_dataset, np.arange(num_train_samples))\n",
    "sample_sampler = RandomSampler(sample_ds)\n",
    "sample_dl = DataLoader(sample_ds, sampler=sample_sampler, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/20000 (0%)]\tLoss: 2.292285\n",
      "Train Epoch: 1 [12800/20000 (64%)]\tLoss: 0.246990\n",
      "\n",
      "Test set: Average loss: 0.0043, Accuracy: 9219/10000 (92%)\n",
      "\n",
      "Train Epoch: 2 [0/20000 (0%)]\tLoss: 0.466618\n",
      "Train Epoch: 2 [12800/20000 (64%)]\tLoss: 0.350250\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 9343/10000 (93%)\n",
      "\n",
      "Train Epoch: 3 [0/20000 (0%)]\tLoss: 0.209156\n",
      "Train Epoch: 3 [12800/20000 (64%)]\tLoss: 0.110871\n",
      "\n",
      "Test set: Average loss: 0.0030, Accuracy: 9429/10000 (94%)\n",
      "\n",
      "Train Epoch: 4 [0/20000 (0%)]\tLoss: 0.120007\n",
      "Train Epoch: 4 [12800/20000 (64%)]\tLoss: 0.197351\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 9490/10000 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/20000 (0%)]\tLoss: 0.167858\n",
      "Train Epoch: 5 [12800/20000 (64%)]\tLoss: 0.072866\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 9607/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/20000 (0%)]\tLoss: 0.078825\n",
      "Train Epoch: 6 [12800/20000 (64%)]\tLoss: 0.059799\n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 9616/10000 (96%)\n",
      "\n",
      "CPU times: user 2min 25s, sys: 272 ms, total: 2min 25s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 7):\n",
    "    train(model, sample_dl, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"Use only 30% of the training dataset.\"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- It is obvious that the accuracy is less than the previous accuracy\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- The speed up is linear\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "The result is worse in the same amount of epochs, this time when I linearly increase the epochs corresponding to the dataset size, the accuracy is 4% less. Therefore this result is worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): Tanh()\n",
       "  (3): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "outputs": [],
   "source": [
    "train_ds = train_dataset\n",
    "num_train_samples = 6000\n",
    "sample_ds = Subset(train_dataset, np.arange(num_train_samples))\n",
    "sample_sampler = RandomSampler(sample_ds)\n",
    "sample_dl = DataLoader(sample_ds, sampler=sample_sampler, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fx878231wz4N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 2.325476\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5):\n",
    "    train(model, sample_dl, optimizer, loss_function, epoch)\n",
    "    test(model, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx878231wz4N"
   },
   "source": [
    "\"Use only 10% of the training dataset.\"\n",
    "\n",
    "##### How does this affect the training process?\n",
    "\n",
    "- Now the dataset is too small to be competing with the trained nets above. It becomes clear a larger dataset is preferable.\n",
    "\n",
    "##### Is it faster slower?\n",
    "\n",
    "- Way faster\n",
    "\n",
    "##### Is the result better or worse?\n",
    "\n",
    "As the accuracy does not converge beyond 92%, the result is a lot worse."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Berend Gort - Practice 2.",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
